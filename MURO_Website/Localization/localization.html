<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="">
    <meta name="author" content="">

    <title>Localization</title>

    <!-- Bootstrap Core CSS -->
    <link rel="stylesheet" href="css_localization/bootstrap.min.css" type="text/css">

    <!-- Custom Fonts -->
    <link href='http://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>
    <link href='http://fonts.googleapis.com/css?family=Merriweather:400,300,300italic,400italic,700,700italic,900,900italic' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" href="font-awesome/css/font-awesome.min.css" type="text/css">

    <!-- Plugin CSS -->
    <link rel="stylesheet" href="css_localization/animate.min.css" type="text/css">

    <!-- Custom CSS -->
    <link rel="stylesheet" href="css_localization/creative.css" type="text/css">

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body id="page-top">

    <nav id="mainNav" class="navbar navbar-default navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header">
                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>
                <a class="navbar-brand page-scroll" href="../index.html">MURO</a>
            </div>

             <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a class="page-scroll" href="../Profiles/profiles.html">Team</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="../Capabilities/capabilities.html">Capabilities</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="../Products/products.html">Implementations</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="../Blog/blog.html">News</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="../Documents/login.html">Documents</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="../index.html#contact">Contact</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <header>
        <div class="header-content">
            <div class="header-content-inner">
                <h1>Localization</h1>
                <h2 class="subheading">  via top-mounted cameras  </h2>
            </div>
        </div>
    </header>


<!-- Post Content -->
    <article>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <p></p>
                    <p></p>
                    <p></p>

                    <h2 class="section-heading">Hardware Set-Up</h2>
                    <a href="#">
                        <img class="img-responsive" src="../img/Webcam.JPG" alt="">
                    </a><br>
		   <span class="caption text-muted"> Webcam</span>
                    <br><br>
                    
                    <hr>
                    
                    <h2 class="section-heading">Localization</h2>
                    <p>The role of the localization subsystem is to provide state estimates of  agents to the larger system. In this specific system configuration, a  webcam mounted on the ceiling is used to provide a video stream to a  computer vision algorithm that finds markers attached to the top of the  robots. The node is capable of delivering both location information in  the form of Cartesian coordinate and heading information describing the  general direction of the robot. Furthermore, the localization scheme is  scalable, so that as the number of agents in the network increases, the  capability is still supported. no man has gone before.</p>

                	<hr>
                	
                	<h2 class="section-heading">Computer Vision Algorithms</h2>
                    <h3 class="subheading">Aruco Library</h3>
                    <p>In the paper, “Automatic generation and detection of highly reliable fiduciary markers under occlusion”, the authors from Cordoba University outline the robust tracking of markers not dissimilar to QR codes. For practical purposes, there are several benefits for our use of this library, including:</p>
                    <ul>
  						<li>Black and white are more easily detected in variable lighting environments</li>
  						<li>Corner detection is relatively robust</li>
  						<li>The ArUco markers have less embedded bits of information than a QR code, making them computationally easier to identify</li>
  						<li>The markers contain information, specifically identification numbers</li>
  						<li>With knowledge of camera intrinsic, it is possible to extrapolate the orientation of the marker with respect to the camera.</li>
					</ul>
		    <br>
                    <a href="#">
                        <img class="img-responsive" src="../img/ArucoMarker.jpg" alt="">
                    </a><br>
		   <span class="caption text-muted">Image of the aruco marker  </span>
                    <br><br><br>
                    <a href="#">
                        <img class="img-responsive" src="../img/ThresholdImage.jpg" alt="">
                    </a><br>
		    <span class="caption text-muted">Edged image after edged texture</span>
                    <br><br><br>
                    <a href="#">
                        <img class="img-responsive" src="../img/LocatedMarker.jpg" alt="">
                    </a><br>
	            <span class="caption text-muted">Need to replace this picture with picture of over head camera</span>
	            <br>
                    <br><br>
                    
                    <p>The basic workings of the localization code are as follows:</p>
		   
                    <ul>
  						<li>The image is passed to the processing node</li>
  						<li>The image is converted to a OpenCV compatible format</li>
  						<li>The ArUco algorithm detects every valid marker</li>
  						<li>For each marker that is found, a state information is published on a separate, robot specific topic</li>
  					</ul>
		
  					
  		    <a href="#">
                        <img class="img-responsive" src="../img/ArucoAlgo.jpg" alt="">
                    </a><br>
	            <span class="caption text-muted">Aruco algorithm flowchart</span>
                    <br>
                    <br><br>
                    
                    <h2 class="section-heading">Extend Kalman Filter (EKF)</h2>
                    <h3 class="subheading">Overview</h3>
                    
                    <!--<font face = "arial">-->
                    <p style="font-family:arial">The extended Kalman Filter (EKF) is a powerful tool for state estimation. It is especially important
                    to have strong state estimations for non-linear unicycle (TurtleBot) dynamics where algorithms are highly
                    dependent on consistent data. The Kalman filter works by estimating the state (our TurtleBot locations and 
                    orientation), <i>x&#770<sub>k|k</sub></i>, by fusing measurement data, <i>y<sub>k</sub></i>, and a predicted 
                    state, <i>x&#770<sub>k|k-1</sub></i>. The EKF provides several functions for the TurtleBots.</p>
                    
                    <p>The EKF provides...</p>
                    
                    <p>1. A state prediction if no measurement data is available.</p
                    
                    <p>A common problem with TurtleBots before the EKF, is that the camera's wont always be able to read the 
                    TurtleBots location. This is due to many factors including the Aruco markers becoming worn out, the angle 
                    of the markers make them more difficult to be detected, or even that the TurtleBots wander outside of the 
                    of the camera's visibility. Using the TurtleBots dynamics, the EKF can provide an prediction for where the 
                    Turtlebots where be in case there is no measurement data. </p>
                    
                    <p>2. A better estimation</p>
                    <p>The Kalman filter is created based on the principle that any two data measurements (or predictions) 
                    can be merged to yield a better estimate. It requires knowledge of how confident we are in the measurement 
                    or prediction that we get (variance). We can always get a better estimate by merging our state prediction and 
                    our measurement data for localization of TurtleBots.</p>
                    
                    <p>3. Provides data for feedback control</p>
                    
                    <p>After experimenting with the TurtleBots, it is apparent that the dynamics fluctuate due to unknown parameters 
                    (could be battery life, part of lab, dust, friction, etc...). The fact that the Turtlebots follow different dynamics 
                    under the same inputs make it increasingly difficult to implement distributed algorithms. One way to deal with this 
                    is to implement integral control. Integral control sums the error over time and modifies the input signal. It is 
                    commonly used to fix steady state error between the estimated state and the reference. The Kalman filter makes 
                    this possible by providing an state prediction, and an estimated state (fusion of state prediction and measured 
                    data). Forcing the difference between the predicted state and the estimated state to be gaussian by modifying 
                    our input forces the TurtleBots to follow a reference signal in a more predictable fashion.  </p>
                    <!--</font>-->
                    
                    <!--<a href="#">
                        <img class="img-responsive" src="img/Overview.jpg" alt="">
                    </a><p></p>
                    <a href="#">
                        <img class="img-responsive" src="img/Par3.jpg" alt="">
                    </a>-->
                    <h3 class="subheading">Theory</h3>
                    
                    <p>Every once in a while, the measurements from the camera are not available. Here are the best estimated locations of a TurtleBot based on state prediction and measurement data as it follows a circle. Red Dots are best estimates when measurements are available. Blue Dots are best estimates when no measurement is available (predicted state)</p>
                    
                    <a href="#">
                        <img class="img-responsive" src="../img/Circle.jpg" alt="">
                    </a>
                    
                    <br>
                    <br>
                    <h3 class="subheading">Implementation</h3>
                    <p></p>
                     <a href="#">
                        <img class="img-responsive" src="../img/Implementation.jpg" alt="">
                    </a>
                    
                    <span class="caption text-muted">
                    1. Camera node detects and publishes robot positions
                    2. Node distributes and identifies robot positions
                    3. Kalman filter calculates best estimated position
                    4a. Best estimated position sent to application
                    4b. Integral variable sent to application
                    </span>
                    <br>
                    <br>
                    <br>
                    <br>
                    <br>


                </div>
            </div>
        </div>
    </article>

 
 
    
    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="js/jquery.easing.min.js"></script>
    <script src="js/jquery.fittext.js"></script>
    <script src="js/wow.min.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/creative.js"></script>

</body>

</html>
